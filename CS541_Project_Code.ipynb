{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "694848b6",
   "metadata": {},
   "source": [
    "### Given data,\n",
    "### 1. Job locations: The locations of the four sites, with site 1 representing the home office and sites 2, 3, and 4 representing remote job sites.  \n",
    "\n",
    "### 2. Equipment trailer cost: The cost of relocating the equipment trailer between the job sites, which is defined as d(j, k) = 300 for k ≠ j.  \n",
    "\n",
    "### 3. Trailer usage cost: The cost of using the trailer for each job, which is defined as 100 if the work is at site k > 1 and trailer is at site j ≠ k with j > 1, 50 if j = k and j > 1, and 200 if the work is at k > 1 and the trailer is at j = 1 (home office).  \n",
    "\n",
    "### 4. Assume the discount factor of 0.95. \n",
    "\n",
    "### 5. Transition matrix: The transition matrix between job locations, which provides the probabilities of moving between the different job sites.  \n",
    "\n",
    "|     | 1    | 2    | 3    | 4    |\n",
    "|-----|------|------|------|------|\n",
    "| **1** | 0.1  | 0.3  | 0.3  | 0.3  |\n",
    "| **2** | 0.0  | 0.5  | 0.5  | 0.0  |\n",
    "| **3** | 0.0  | 0.0  | 0.8  | 0.2  |\n",
    "| **4** | 0.4  | 0.0  | 0.0  | 0.6  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea3fc10",
   "metadata": {},
   "source": [
    "### Method 1 : Obtain optimal policy and optimal value function by value iteration and calculate lower and upper bounds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5e1e434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Policy:\n",
      "1 4 2 2\n",
      "2 2 2 2\n",
      "3 3 2 3\n",
      "4 4 4 2\n",
      "\n",
      "Optimal Value Function (v*):\n",
      "[[186.33667797 234.48030831 169.46946549 187.75090855]\n",
      " [ 99.29708312 158.09141942  69.46946549  87.75090855]\n",
      " [140.85459985 153.32951466 169.46946549 124.47615589]\n",
      " [148.28419178 134.48030831 148.63613215 187.75090855]]\n",
      "\n",
      "Lower Bounds (v_lo):\n",
      "[[3540.39688139 4455.12585791 3219.91984422 3567.26726254]\n",
      " [1886.64457937 3003.73696902 1319.91984422 1667.26726254]\n",
      " [2676.23739709 2913.26077855 3219.91984422 2365.04696192]\n",
      " [2817.39964383 2555.12585791 2824.08651089 3567.26726254]]\n",
      "\n",
      "Upper Bounds (v_up):\n",
      "[[3540.39688139 4455.12585791 3219.91984422 3567.26726254]\n",
      " [1886.64457937 3003.73696902 1319.91984422 1667.26726254]\n",
      " [2676.23739709 2913.26077855 3219.91984422 2365.04696192]\n",
      " [2817.39964383 2555.12585791 2824.08651089 3567.26726254]]\n",
      "\n",
      "Average Reward per Step: 149.99546959917066\n",
      "\n",
      "Total Cost: 2399.9275135867306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ratan\\AppData\\Local\\Temp\\ipykernel_18956\\2226667210.py:60: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  policy = np.zeros((num_states, num_states), dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_cost(j, k, u):\n",
    "    if k == 1 and u == j:\n",
    "        return 0\n",
    "    elif k > 1 and u == j == 1:\n",
    "        return 200\n",
    "    elif k == u == j > 1:\n",
    "        return 50\n",
    "    elif k > 1 and u != j and u != k:\n",
    "        return 100\n",
    "    elif k == 1 and u != j:\n",
    "        return 300\n",
    "    elif k > 1 and u == 1 and j != 1:\n",
    "        return 500\n",
    "    elif k > 1 and u == k and j != k:\n",
    "        return 350\n",
    "    elif k > 1 and (u == 1 or u == k) and j != u:\n",
    "        return 400\n",
    "    else:\n",
    "        return 0  # or a value that makes sense in your context\n",
    "\n",
    "def value_iteration(P, discount_factor, tolerance=1e-6):\n",
    "    num_states = P.shape[0]\n",
    "    \n",
    "    # Initialize the value functions\n",
    "    V = np.zeros((num_states, num_states))\n",
    "    V_lo = np.zeros((num_states, num_states))\n",
    "    V_up = np.zeros((num_states, num_states))\n",
    "    \n",
    "    while True:\n",
    "        V_prev = V.copy()\n",
    "        V_delta = np.zeros((num_states, num_states))\n",
    "        \n",
    "        for j in range(num_states):\n",
    "            for k in range(num_states):\n",
    "                min_cost = float('inf')\n",
    "                for u in range(num_states):\n",
    "                    cost = calculate_cost(j + 1, k + 1, u + 1)\n",
    "                    \n",
    "                    expected_value = 0\n",
    "                    for l in range(num_states):\n",
    "                        expected_value += P[k, l] * V_prev[u, l]\n",
    "                    \n",
    "                    value = cost + discount_factor * expected_value\n",
    "                    min_cost = min(min_cost, value)\n",
    "                \n",
    "                V[j, k] = min_cost\n",
    "                V_lo[j, k] += (discount_factor / (1 - discount_factor)) * (V[j, k] - V_prev[j, k])\n",
    "                V_up[j, k] += (discount_factor / (1 - discount_factor)) * (V[j, k] - V_prev[j, k])\n",
    "                V_delta[j, k] = abs(V[j, k] - V_prev[j, k])\n",
    "        \n",
    "        if np.max(V_delta) < tolerance:\n",
    "            break\n",
    "    \n",
    "    return V, V_lo, V_up\n",
    "\n",
    "def get_optimal_policy(V, P, discount_factor):\n",
    "    num_states = V.shape[0]\n",
    "    policy = np.zeros((num_states, num_states), dtype=np.int)\n",
    "    \n",
    "    for j in range(num_states):\n",
    "        for k in range(num_states):\n",
    "            min_cost = float('inf')\n",
    "            best_action = None\n",
    "            \n",
    "            for u in range(num_states):\n",
    "                cost = calculate_cost(j + 1, k + 1, u + 1)\n",
    "                \n",
    "                expected_value = 0\n",
    "                for l in range(num_states):\n",
    "                    expected_value += P[k, l] * V[u, l]\n",
    "                \n",
    "                if cost + discount_factor * expected_value < min_cost:\n",
    "                    min_cost = cost + discount_factor * expected_value\n",
    "                    best_action = u\n",
    "            \n",
    "            policy[j, k] = best_action\n",
    "    \n",
    "    return policy\n",
    "\n",
    "def print_optimal_policy(policy):\n",
    "    num_states = policy.shape[0]\n",
    "    print(\"\\nOptimal Policy:\")\n",
    "    for j in range(num_states):\n",
    "        policy_row = \" \".join(str(action + 1) for action in policy[j])\n",
    "        print(policy_row)\n",
    "\n",
    "\n",
    "# Transition matrix\n",
    "P = np.array([\n",
    "    [0.1, 0.3, 0.3, 0.3],\n",
    "    [0.0, 0.5, 0.5, 0.0],\n",
    "    [0.0, 0.0, 0.8, 0.2],\n",
    "    [0.4, 0.0, 0.0, 0.6]\n",
    "])\n",
    "\n",
    "discount_factor = 0.95\n",
    "\n",
    "# Perform value iteration\n",
    "V, V_lo, V_up = value_iteration(P, discount_factor)\n",
    "\n",
    "# Calculate average reward per step\n",
    "average_reward = np.mean(V)\n",
    "\n",
    "# Calculate total cost\n",
    "total_cost = np.sum(V)\n",
    "\n",
    "# Calculate and print the optimal policy\n",
    "policy = get_optimal_policy(V, P, discount_factor)\n",
    "print_optimal_policy(policy)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nOptimal Value Function (v*):\")\n",
    "print(V)\n",
    "print(\"\\nLower Bounds (v_lo):\")\n",
    "print(V_lo)\n",
    "print(\"\\nUpper Bounds (v_up):\")\n",
    "print(V_up)\n",
    "print(\"\\nAverage Reward per Step:\", average_reward)\n",
    "print(\"\\nTotal Cost:\", total_cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b2bd90",
   "metadata": {},
   "source": [
    "### Method 2: Obtain optimal policy and optimal value function by policy iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce07a51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy:\n",
      "[[0 3 1 1]\n",
      " [1 1 1 1]\n",
      " [2 2 1 2]\n",
      " [3 3 3 1]]\n",
      "\n",
      "Optimal Value Function:\n",
      "[[186.33669616 234.4803265  169.46948368 187.75092675]\n",
      " [ 99.29710132 158.09143762  69.46948368  87.75092675]\n",
      " [140.85461954 153.32953285 169.46948368 124.47617746]\n",
      " [148.28420997 134.4803265  148.63615035 187.75092675]]\n",
      "\n",
      "Average Reward per Step: 149.99548809740222\n",
      "\n",
      "Total Cost: 2399.9278095584355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ratan\\AppData\\Local\\Temp\\ipykernel_18956\\4229978039.py:28: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  policy = np.zeros((num_states, num_states), dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_cost(j, k, u):\n",
    "    if k == 1 and u == j:\n",
    "        return 0\n",
    "    elif k > 1 and u == j == 1:\n",
    "        return 200\n",
    "    elif k == u == j > 1:\n",
    "        return 50\n",
    "    elif k > 1 and u != j and u != k:\n",
    "        return 100\n",
    "    elif k == 1 and u != j:\n",
    "        return 300\n",
    "    elif k > 1 and u == 1 and j != 1:\n",
    "        return 500\n",
    "    elif k > 1 and u == k and j != k:\n",
    "        return 350\n",
    "    elif k > 1 and (u == 1 or u == k) and j != u:\n",
    "        return 400\n",
    "    else:\n",
    "        return 0  # or a value that makes sense in your context\n",
    "\n",
    "def policy_iteration(P, discount_factor, max_iterations=1000):\n",
    "    num_states = P.shape[0]\n",
    "    num_actions = P.shape[1]\n",
    "    \n",
    "    # Initialize the policy and value functions\n",
    "    policy = np.zeros((num_states, num_states), dtype=np.int)\n",
    "    value_function = np.zeros((num_states, num_states))\n",
    "    \n",
    "    for _ in range(max_iterations):\n",
    "        # Policy evaluation\n",
    "        while True:\n",
    "            new_value_function = np.copy(value_function)\n",
    "            \n",
    "            for j in range(num_states):\n",
    "                for k in range(num_states):\n",
    "                    u = policy[j, k]\n",
    "                    cost = calculate_cost(j + 1, k + 1, u + 1)\n",
    "                    \n",
    "                    expected_value = 0\n",
    "                    for l in range(num_states):\n",
    "                        expected_value += P[k, l] * value_function[u, l]\n",
    "                    \n",
    "                    new_value_function[j, k] = cost + discount_factor * expected_value\n",
    "            \n",
    "            if np.max(np.abs(value_function - new_value_function)) < 1e-6:\n",
    "                break\n",
    "            \n",
    "            value_function = new_value_function\n",
    "        \n",
    "        # Policy improvement\n",
    "        policy_stable = True\n",
    "        \n",
    "        for j in range(num_states):\n",
    "            for k in range(num_states):\n",
    "                current_action = policy[j, k]\n",
    "                min_cost = float('inf')\n",
    "                best_action = None\n",
    "                \n",
    "                for u in range(num_actions):\n",
    "                    cost = calculate_cost(j + 1, k + 1, u + 1)\n",
    "                    \n",
    "                    expected_value = 0\n",
    "                    for l in range(num_states):\n",
    "                        expected_value += P[k, l] * value_function[u, l]\n",
    "                    \n",
    "                    if cost + discount_factor * expected_value < min_cost:\n",
    "                        min_cost = cost + discount_factor * expected_value\n",
    "                        best_action = u\n",
    "                \n",
    "                if best_action != current_action:\n",
    "                    policy_stable = False\n",
    "                    policy[j, k] = best_action\n",
    "        \n",
    "        if policy_stable:\n",
    "            break\n",
    "    \n",
    "    return policy, value_function\n",
    "\n",
    "# Transition matrix\n",
    "P = np.array([\n",
    "    [0.1, 0.3, 0.3, 0.3],\n",
    "    [0.0, 0.5, 0.5, 0.0],\n",
    "    [0.0, 0.0, 0.8, 0.2],\n",
    "    [0.4, 0.0, 0.0, 0.6]\n",
    "])\n",
    "\n",
    "discount_factor = 0.95\n",
    "\n",
    "policy, value_function = policy_iteration(P, discount_factor)\n",
    "\n",
    "# Calculate average reward per step\n",
    "average_reward = np.mean(value_function)\n",
    "\n",
    "# Calculate total cost\n",
    "total_cost = np.sum(value_function)\n",
    "\n",
    "print(\"Optimal Policy:\")\n",
    "print(policy)\n",
    "\n",
    "print(\"\\nOptimal Value Function:\")\n",
    "print(value_function)\n",
    "\n",
    "print(\"\\nAverage Reward per Step:\", average_reward)\n",
    "print(\"\\nTotal Cost:\", total_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b29765",
   "metadata": {},
   "source": [
    "### Method 3: Obtain optimal policy and optimal value function by linear programming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e54ab690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Value Function (v*):\n",
      "[[186.3367   234.48033  169.46948  187.75093 ]\n",
      " [ 99.297101 158.09144   69.469484  87.750927]\n",
      " [140.85462  153.32953  169.46948  124.47617 ]\n",
      " [148.28421  134.48033  148.63615  187.75093 ]]\n",
      "\n",
      "Optimal Policy:\n",
      "[[4 2 3 4]\n",
      " [1 1 3 4]\n",
      " [1 2 1 4]\n",
      " [1 2 3 1]]\n",
      "\n",
      "Average Cost per Step:  149.99548825\n",
      "\n",
      "Total Rewards:  2399.927812\n"
     ]
    }
   ],
   "source": [
    "from pulp import *\n",
    "import numpy as np\n",
    "\n",
    "# Define the step-wise cost function c(j, k, u)\n",
    "def c(j, k, u):\n",
    "    if k == 1 and u == j:\n",
    "        return 0\n",
    "    elif k > 1 and u == j == 1:\n",
    "        return 200\n",
    "    elif k == u == j > 1:\n",
    "        return 50\n",
    "    elif k > 1 and u != j and u != k:\n",
    "        return 100\n",
    "    elif k == 1 and u != j:\n",
    "        return 300\n",
    "    elif k > 1 and u == 1 and j != 1:\n",
    "        return 500\n",
    "    elif k > 1 and u == k and j != k:\n",
    "        return 350\n",
    "    elif k > 1 and (u == 1 or u == k) and j != u:\n",
    "        return 400\n",
    "    else:\n",
    "        return 0  # Return 0 for any other combination of j, k, u\n",
    "\n",
    "# Define the discount factor α\n",
    "α = 0.95\n",
    "\n",
    "# Define the transition probabilities p_kl\n",
    "p = [[0.1, 0.3, 0.3, 0.3],\n",
    "     [0.0, 0.5, 0.5, 0.0],\n",
    "     [0.0, 0.0, 0.8, 0.2],\n",
    "     [0.4, 0.0, 0.0, 0.6]]\n",
    "\n",
    "# Define the state and control spaces\n",
    "states = list(range(1, len(p) + 1))\n",
    "controls = list(range(1, len(p[0]) + 1))\n",
    "\n",
    "# Create the LP problem\n",
    "prob = LpProblem(\"OptimalValueFunction\", LpMaximize)\n",
    "\n",
    "# Define the decision variables\n",
    "v = LpVariable.dicts(\"v\", (states, states), lowBound=0)\n",
    "\n",
    "# Set the objective function\n",
    "prob += lpSum([v[j][k] for j in states for k in states])\n",
    "\n",
    "# Add the constraints\n",
    "for j in states:\n",
    "    for k in states:\n",
    "        for u in controls:\n",
    "            prob += v[j][k] <= c(j, k, u) + α * lpSum([p[k - 1][l - 1] * v[u][l] for l in states])\n",
    "\n",
    "# Solve the LP problem\n",
    "prob.solve()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "total_rewards = value(prob.objective)\n",
    "average_cost_per_step = total_rewards / (len(states) ** 2)\n",
    "\n",
    "# Create arrays for optimal value function and optimal policy\n",
    "optimal_value_function = np.zeros((len(states), len(states)))\n",
    "optimal_policy = np.zeros((len(states), len(states)), dtype=int)\n",
    "\n",
    "# Store optimal value function and optimal policy\n",
    "for j in states:\n",
    "    for k in states:\n",
    "        optimal_value_function[j - 1][k - 1] = value(v[j][k])\n",
    "        max_action = max(controls, key=lambda u: c(j, k, u) + α * sum([p[k - 1][l - 1] * value(v[u][l]) for l in states]))\n",
    "        optimal_policy[j - 1][k - 1] = max_action\n",
    "\n",
    "# Print the optimal value function as array\n",
    "print(\"Optimal Value Function (v*):\")\n",
    "print(optimal_value_function)\n",
    "\n",
    "# Print the optimal policy as array\n",
    "print(\"\\nOptimal Policy:\")\n",
    "print(optimal_policy)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"\\nAverage Cost per Step: \", average_cost_per_step)\n",
    "print(\"\\nTotal Rewards: \", total_rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
